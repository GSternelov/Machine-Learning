---
title: "Introduction to Machine Learning - Lab 3"
author: "Gustav Sternel√∂v"
date: "Sunday, November 08, 2015"
output:
  pdf_document:
    fig_height: 4
    fig_width: 7
---

## Assignment 1
In the first assignment a data material named australian crabs is analysed. It contanis information about measurements of the frontal lobe, rear witdh etc. for 200 crabs. 

### 1.1
A scatterplot visualizing the carapace length versus rear width.  

```{r, echo=FALSE, warning=FALSE}
aussieCrab <- read.csv("australian-crabs.csv", sep=",", header = TRUE)

library(ggplot2)
ggplot(aussieCrab, aes(y=CL, x=RW)) + geom_point(aes(color=sex), size=3)

```


For values of RW higher than 12.5 and values of CL higher than 30 this data should be easy to classify by linear discriminant analysis. For lower values the obseervations lies closer and it will problaby be harder to find a linear decision boundary that classifies all those observations correctly. 

### 1.2

```{r, echo=FALSE}
# 1.2

male_data <- subset(aussieCrab, sex=="Male")[5:6]
female_data <- subset(aussieCrab, sex=="Female")[5:6]

male_vec <- c(mean(male_data[,1]), mean(male_data[,2]))
female_vec <- c(mean(female_data[,1]), mean(female_data[,2]))

male_cov <- cov(male_data)
female_cov <- cov(female_data)

covHat <- matrix(100/200 * male_cov + 100/200 * female_cov, ncol=2)

# prop priors
prior_male <- 100/200
prior_female <- 100/200

W_male <- (as.matrix(aussieCrab[, 5:6]))%*% solve(covHat) %*% as.matrix(male_vec) 
Wo_male <-  (0.5 *  t(as.matrix(male_vec)) %*% solve(covHat) %*% as.matrix(male_vec) +
  log(prior_male))
disc_male <- W_male - as.vector(Wo_male)

W_female <- (as.matrix(aussieCrab[, 5:6]))%*% solve(covHat)%*% as.matrix(female_vec) 
Wo_female <- (0.5 *  t(as.matrix(female_vec)) %*% solve(covHat) %*% as.matrix(female_vec) +
   log(prior_female))
disc_female <-W_female - as.vector(Wo_female)

classif <- 0
for(i in 1:200){
  if(disc_male[i] > disc_female[i]){
    classif[i] = "male"
  }else{
    classif[i] = "female"
  }
}

```

 
The respective discriminant function for males and females looks as follows:
$$\delta(x)_{male} = x^T\Sigma^{-1} \mu_{male} - \frac{1}{2} \mu^T_{male}\Sigma^{-1} \mu_{male}+ log \pi_{male} = x^T w_i - w_{0male}$$
$$\delta(x)_{female} = x^T\Sigma^{-1}$$

And the decision boundary is given by the this expression : CL = 2.91RW - 5.06  

### 1.3
In the following plot the observed values of RW and CL are visualized. Colours are given after the classification label and shape after the true class for the observations. The red line gives the decision boundary.  

```{r, echo=FALSE}
#table(classif, aussieCrab$sex)
lda_class <- data.frame(aussieCrab, classif)

ggplot(lda_class, aes(y=CL, x=RW)) + 
  geom_point(aes(color=classif,shape=sex), size=4) +
  geom_abline(intercept = -5.06, slope=2.91, colour="red")

```

The fit is considered to be pretty god. Only 7 of 200 observations is classified wrongly, and as expected most of these observations are find at the bottom left of the plot. 

### 1.4

Another method to classify the observations are by a logistic regression model. In the graph below the classifications are plotted in the same way as in 1.3.  

```{r, echo=FALSE, warning=FALSE}
logi_class <- glm(sex~RW+CL,data=aussieCrab, family=binomial())
#summary(logi_class)
#exp(coef(logi_class))
pred_logi <- data.frame(aussieCrab$RW,aussieCrab$CL,aussieCrab$sex , predict(logi_class, type="response"))

for (i in 1:length(pred_logi[,4])){
if(pred_logi[,4][i] <0.5){
  pred_logi[,4][i] = 0
}else{
  pred_logi[,4][i] = 1
} }

for (i in 1:length(pred_logi[,4])){
  if(pred_logi[,4][i] == 0){
    pred_logi[,4][i] = "Female"
  }else{
    pred_logi[,4][i] = "Male"
  } }

ggplot(pred_logi, aes(y=aussieCrab.CL, x=aussieCrab.RW)) + 
  geom_point(aes(color=pred_logi[,4],shape=aussieCrab.sex), size=4) +
  geom_abline(intercept = -2.94, slope=2.713, colour="red")


#table(pred_logi[,4], pred_logi$aussieCrab.sex)
```
 
The decision boundary for the logistic regression model: CL = 2.713RW - 2.94  
The obtained result with logistic regression is very similar to the result given with the *lda* model. For both models seven observations has been misclassified, and even though the decision boundaries are different it is first and foremost at the bottom left of the graph the misclassified observations can be found. A comparsion of the lines for the two models decision boundaries gives that the line for the logistic model is slightly shifted because . 

## Assignment 2
For the second assignment the analyzed data contains information about how well costumers have managed their loans. The costumers are divided into two classes, good or bad borrowers, and there is 19 different potential features that can be used for classifying.

### 2.1 - 2,2
To start with, data is splitted into a training, validation and test data set. 
```{r, echo=FALSE}
creditScore <- read.csv("creditscoring.csv", sep=";", header = TRUE) 

# create train set
n=dim(creditScore)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=creditScore[id,]
test=creditScore[-id,]

# create valid and test
n=dim(test)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
valid=test[id,]
test=test[-id,]
```


```{r, echo=FALSE, warning=FALSE}
library(tree)
# a) - deviance
# train
deviFit <- tree(good_bad~., data=train, split="deviance")
#plot(deviFit)
#text(deviFit, pretty=0)
#deviFit
devi_summary <- summary(deviFit)
deviPred <- predict(deviFit, newdata=test, type="class")
deviTable <- table(test$good_bad, deviPred)

# b) gini index
# train
giniFit <- tree(good_bad~., data=train, split="gini")
gini_summary <- summary(giniFit)
giniPred <- predict(giniFit, newdata=test, type="class")
giniTable <- table(test$good_bad, giniPred)

# Lower misclassification for deviance
```
Decision tree is the first classification method used to classify the costumers. When a decision tree is fitted one of the choices is which impurity measure to use. Here two different models, one with deviance and one with gini as measure, is compared.  

For training data with deviance as measure of impurity the misclassification rate is `r devi_summary$misclass[1] / devi_summary$misclass[2]` and for test data the misclassification rate is `r (deviTable [2,1] + deviTable[1,2]) / sum(diag(deviTable))`. With gini as impurity measure the rate is `r gini_summary$misclass[1] / gini_summary$misclass[2]` for training data and `r (giniTable [2,1] + giniTable[1,2]) / sum(diag(giniTable))` for test data.
Since the misclassification rate is lower in the first case deviance is the chosen measure for the upcoming steps. 


### 2.3
Red line is value for training data and blue line for test data. If the optimal number of leaves is set to 4, has lowest score, the optimal tree has a depth of 3 (?) and includes the variables savings, duration and history. 

**Interpret the information provided by the tree structure. **

Misclassification rate is 0.251 for training data and 0.256 for test data. Compared to the unpruned tree the rates its significantly lower for the pruned tree. 

```{r, echo=FALSE}
trainScore <- rep(0,15)
testScore <- rep(0,15)

for (i in 2:15){
  prunedTree <- prune.tree(deviFit, best=i)
  pred <- predict(prunedTree, newdata=valid,
               type="tree")
  trainScore[i] <- deviance(prunedTree)
  testScore[i] <- deviance(pred)
}

plot(2:15, trainScore[2:15], type="b", col="red", ylim=c(250,550))
points(2:15, testScore[2:15], type="b", col="blue")
# Which is the optimal number of leaves?
# A try with optimal number of leaves set to 12
finalTree <- prune.tree(deviFit, best=4)
# The variables used
summary(finalTree)
# Model tested on test data
NewFit <- predict(finalTree, newdata=test, type="class")
NewFitTable <- table(test$good_bad, NewFit)
```


### 2.4
```{r, echo=FALSE, warning=FALSE}
library(e1071)
# bayes classifier based on training data
bayesFit <- naiveBayes(good_bad~., data=train)
# Fitted valuse for training and test based on classifier
bayesPredTrain <- predict(bayesFit, newdata=train)
bayesPredTest <- predict(bayesFit, newdata=test)
# confusion matrices for train and test
bayesTrain <-table(train$good_bad, bayesPredTrain)
bayesTest <- table(test$good_bad, bayesPredTest)
```

In 2.4 the classification of the costumers is performed with the Naive Bayes classifier. The first of the tables below gives the confusion matrix for training data and the second for test data. For training data the misclassification rate is `r (bayesTrain [2,1] + bayesTrain[1,2]) / sum(diag(bayesTrain))` and for test data it is `r (bayesTest [2,1] + bayesTest[1,2]) / sum(diag(bayesTest))`. Compared to the results in 2.3 these rates are higher by quite a clear margin. 

```{r, echo=FALSE}
bayesTrain
bayesTest
```

### 2.5
Naive Bayes classification is again used, but now with a loss function defiend as following:  

$$ L = \begin{array} {rrr}good \\bad \end{array}
\left[\begin{array} {rrr} 0 & 1 \\ 10 & 0 \end{array}\right] $$
With this function the confusion matrices seen below is obtained for train and test data. The misclassification rate for training data is ... and for test data...
```{r, echo=FALSE}
# Repeating 2.4 but with a defined loss matrix. 
raws <- data.frame(predict(bayesFit, newdata=train, type="raw"))

preds <- 0
for (i in 1:500){
  if((raws[i,1]/raws[i,2]) > 0.1){
    preds[i] = "bad"
  }else{
    preds[i] ="good"
  }  
}

table(train$good_bad, preds)

rawTest <- predict(bayesFit, newdata=test, type="raw")
preds <- 0
for (i in 1:250){
  if((rawTest[i,1]/rawTest[i,2]) > 0.1){
    preds[i] = "bad"
  }else{
    preds[i] ="good"
  }  
}

table(test$good_bad, preds)

```
The misclassification rate for training data is ... and for test data ... . This implies that the Naive Bayes classification under the assumption of the loss function stated above is better/worse than the classifier used in 2.4. 
The loss function changes the decision boundary for the classification and thereby also the probability for different types of errors. This can be seen in the results were the amount of costumers that is wrongly classified as... is low and the amount of costumers wrongly classified as... is much higher now. 